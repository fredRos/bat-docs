<!-- HTML header for doxygen 1.8.8-->
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
    <head>
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <!-- For Mobile Devices -->
        <meta name="viewport" content="width=device-width, initial-scale=1">
        <meta http-equiv="Content-Type" content="text/xhtml;charset=UTF-8"/>
        <meta name="generator" content="Doxygen 1.8.11"/>
        <script type="text/javascript" src="https://code.jquery.com/jquery-2.1.1.min.js"></script>
        <title>BAT manual: Markov chain Monte Carlo</title>
        <!--<link href="tabs.css" rel="stylesheet" type="text/css"/>-->
        <script type="text/javascript" src="dynsections.js"></script>
        <link href="search/search.css" rel="stylesheet" type="text/css"/>
<script type="text/javascript" src="search/searchdata.js"></script>
<script type="text/javascript" src="search/search.js"></script>
<script type="text/javascript">
  $(document).ready(function() { init_search(); });
</script>
        <script type="text/x-mathjax-config">
  MathJax.Hub.Config({
    extensions: ["tex2jax.js", "TeX/AMSmath.js", "TeX/AMSsymbols.js"],
    jax: ["input/TeX","output/HTML-CSS"],
});
MathJax.Hub.Config({
    TeX: {
        Macros: {
            cond: ["{\\,|\\,}"],
            rmdx: ["{\\mbox{d}#1\\,}",1],
            scath: ["{\\theta}"],
            vecth: ["{\\boldsymbol{\\theta}}"],
            order: ["{\\mathcal{O}(#1)}",1],
        }
    }
});
</script><script type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.4/latest.js?config=TeX-MML-AM_CHTML/MathJax.js"></script>
        <link href="doxygen.css" rel="stylesheet" type="text/css" />
        <link href="customdoxygen.css" rel="stylesheet" type="text/css"/>
        <link href='https://fonts.googleapis.com/css?family=Roboto+Slab' rel='stylesheet' type='text/css'>
        <link rel="stylesheet" href="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/css/bootstrap.min.css">
        <script src="https://maxcdn.bootstrapcdn.com/bootstrap/3.3.1/js/bootstrap.min.js"></script>
        <script type="text/javascript" src="doxy-boot.js"></script>
    </head>
    <body>
        <nav class="navbar navbar-default" role="navigation">
            <div class="container">
                <div class="navbar-header">
                    <a class="navbar-brand">BAT manual 1.0.0-RC2</a>
                </div>
            </div>
        </nav>
        <div id="top"><!-- do not remove this div, it is closed by doxygen! -->
            <div class="content" id="content">
                <div class="container">
                    <div class="row">
                        <div class="col-sm-12 panel " style="padding-bottom: 15px;">
                            <div style="margin-bottom: 15px;">
<!-- end header part -->
<!-- Generated by Doxygen 1.8.11 -->
<script type="text/javascript">
var searchBox = new SearchBox("searchBox", "search",false,'Search');
</script>
  <div id="navrow1" class="tabs">
    <ul class="tablist">
      <li><a href="index.html"><span>Overview</span></a></li>
      <li class="current"><a href="pages.html"><span>Chapters</span></a></li>
      <li>
        <div id="MSearchBox" class="MSearchBoxInactive">
        <span class="left">
          <img id="MSearchSelect" src="search/mag_sel.png"
               onmouseover="return searchBox.OnSearchSelectShow()"
               onmouseout="return searchBox.OnSearchSelectHide()"
               alt=""/>
          <input type="text" id="MSearchField" value="Search" accesskey="S"
               onfocus="searchBox.OnSearchFieldFocus(true)" 
               onblur="searchBox.OnSearchFieldFocus(false)" 
               onkeyup="searchBox.OnSearchFieldChange(event)"/>
          </span><span class="right">
            <a id="MSearchClose" href="javascript:searchBox.CloseResultsWindow()"><img id="MSearchCloseImg" border="0" src="search/close.png" alt=""/></a>
          </span>
        </div>
      </li>
    </ul>
  </div>
<!-- window showing the filter options -->
<div id="MSearchSelectWindow"
     onmouseover="return searchBox.OnSearchSelectShow()"
     onmouseout="return searchBox.OnSearchSelectHide()"
     onkeydown="return searchBox.OnSearchSelectKey(event)">
</div>

<!-- iframe showing the search results (closed by default) -->
<div id="MSearchResultsWindow">
<iframe src="javascript:void(0)" frameborder="0" 
        name="MSearchResults" id="MSearchResults">
</iframe>
</div>

</div><!-- top -->
<div class="header">
  <div class="headertitle">
<div class="title">Markov chain Monte Carlo </div>  </div>
</div><!--header-->
<div class="contents">
<div class="toc"><h3>Table of Contents</h3>
<ul><li class="level1"><a href="#sec-mcmc-motiv">Motivation</a></li>
<li class="level1"><a href="#sec-mcmc-integration">Monte Carlo integration</a></li>
<li class="level1"><a href="#sec-mcmc-foundations">Foundations</a></li>
<li class="level1"><a href="#sec-convergence">Convergence</a></li>
<li class="level1"><a href="#sec-mcmc-impl">Implementation in BAT</a><ul><li class="level2"><a href="#sec-mcmc-prerun">Prerun</a><ul><li class="level3"><a href="#sec-mcmc-eff">Efficiency</a></li>
<li class="level3"><a href="#sec-mcmc-Rvalue">R value</a></li>
<li class="level3"><a href="#sec-mcmc-prerun-length">Prerun length</a></li>
</ul>
</li>
<li class="level2"><a href="#sec-mcmc-proposal">Proposal functions</a><ul><li class="level3"><a href="#sec-factorized">Factorized proposal</a></li>
<li class="level3"><a href="#sec-multivariate">Multivariate proposal</a></li>
</ul>
</li>
<li class="level2"><a href="#sec-mcmc-proposal-comparison">Comparison</a></li>
</ul>
</li>
</ul>
</div>
<div class="textblock"><dl class="todo"><dt><b><a class="el" href="todo.html#_todo000005">Todo:</a></b></dt><dd>workhorse of BAT. mention Metropolis algorithm, role of proposal function, different choices in bat, why it has to be adapted in prerun. What else happens in prerun:R value and convergence checking. Mention that samples are correlated, chains can get stuck if model wrong/poor.</dd></dl>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000006">Todo:</a></b></dt><dd>overlap with chapter on integration </dd></dl>
<h1><a class="anchor" id="sec-mcmc-motiv"></a>
Motivation</h1>
<p>The reason that BAT exists is that nearly any Bayesian analysis these days is too complicated to be handled analytically. To address typical questions like</p>
<ul>
<li>What is known about a single parameter taking into account the uncertainty on all other parameters?</li>
<li>How are parameters correlated?</li>
</ul>
<p>one needs to be able to compute and visualize 1D and 2D <em>marginal distributions</em>; cf. <a class="el" href="cha-Bayes.html#sec-marginalization">Marginalization</a>. These are defined as integrals over the posterior; for example in 2D </p><p class="formulaDsp">
\begin{align} \label{eq:mcmc-marginal} P(\theta_1, \theta_2 \cond D) = \int \prod_{i \ne 1,2} \rmdx{\theta_i} P(\vecth \cond D). \end{align}
</p>
<p> Therefore Bayesian inference in practice requires good integration techniques.</p>
<p>For low-dimensional problems, deterministic integration methods are usually the fastest and most robust. For marginalization, BAT defaults to evaluating on a grid, that is Riemann integration, for 1D and 2D problems.</p>
<dl class="section see"><dt>See also</dt><dd>BCIntegrate::SetMarginalizationMethod(BCIntegrate::kMargGrid)</dd></dl>
<p>When the number of parameters grows, the only feasible algorithms to perform the integration are Monte Carlo methods; i.e., methods based on random numbers.</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000007">Todo:</a></b></dt><dd>explain in general the idea of Monte Carlo integration, grid for low dimensions default in BAT</dd></dl>
<h1><a class="anchor" id="sec-mcmc-integration"></a>
Monte Carlo integration</h1>
<p>We begin with the <em>fundamental Monte Carlo</em> principle. Suppose we have a probability density \(P(\vecth)\), often called the <em>target</em> density, and an arbitrary function \(f(\vecth)\) with finite expectation value under \(P\) </p><p class="formulaDsp">
\begin{align} \label{eq:mc-expect} E_P[ f ] = \int \rmdx{ \vecth} P(\vecth) f(\vecth) &lt; \infty . \end{align}
</p>
<p> Then a set of draws \(\{ \vecth_i:i=1 \dots N \}\) from the density \(P\), that is \(\vecth_i \sim P\), is enough to estimate the expectation value. Specifically, the integral can be replaced by the estimator (distinguished by the symbol \(\widehat{\phantom{a}}\)) </p><p class="formulaDsp">
\begin{align} \label{eq:mc-expect-discrete} \boxed{ \widehat{E_P[f]} \approx \frac{1}{N} \sum_{i=1}^{N} f(\vecth_i), \; \vecth \sim P } \end{align}
</p>
<p> As \(N \to \infty\), the estimate converges almost surely at a rate \(\propto 1/\sqrt{N}\) by the strong law of large numbers if \(\int \rmdx{ \vecth} P(\vecth) f^2(\vecth) &lt; \infty\) <a class="el" href="citelist.html#CITEREF_Casella:2004">[10]</a> .</p>
<p><a class="anchor" id="mcmc-histogram"></a></p><div class="image">
<img src="histogram.png" alt="histogram.png"/>
<div class="caption">
Histogram approximation to the 1D marginal.</div></div>
<p>How does this relate to Bayesian inference? Upon applying Bayes’ theorem to real-life problems, one usually has to marginalize over several parameters, and this can usually not be done analytically, hence one has to resort to numerical techniques. In low dimensions, say \(d \le 2\), quadrature and other grid-based methods are fast and accurate, but as \(d\) increases, these methods generically suffer from the <em>curse of dimensionality</em>. The number of function evaluations grows exponentially as \(\order{m^d}\), where \(m\) is the number of grid points in one dimension. Though less accurate in few dimensions, Monte Carlo — i.e., random-number based — methods are the first choice in \(d \gtrsim 3\) because the computational complexity is (at least in principle) independent of \(d\). Which function \(f\) is of interest to us? For example when integrating over all but the first dimension of \(\vecth\), the marginal posterior probability that \(\theta_1\) is in \([a,b]\) can be estimated as</p>
<p class="formulaDsp">
\[ \label{eq:disc-marg} P(a \le \theta_1 \le b|D) \approx \frac{1}{N} \sum_{i=1}^{N} \mathbf{1}_{\theta_1 \in [a,b]} (\vecth_i) \, \]
</p>
<p> with the <em>indicator function</em> </p><p class="formulaDsp">
\[ \label{eq:indicator-fct} \mathbf{1}_{\theta_1 \in [a,b]} (\vecth) = \begin{cases} 1, \theta_1 \in [a,b] \\ 0, {\rm else} \end{cases} \]
</p>
<p>This follows immediately from the Monte Carlo principle with \(f(\vecth) = \mathbf{1}_{\theta_1 \in [a,b]}(\vecth)\). The major simplification arises as we perform the integral over \(d-1\) dimensions simply by ignoring these dimensions in the indicator function. If the parameter range of \(\theta_1\) is partitioned into bins, then the above holds in every bin, and defines the histogram approximation to \(P(\theta_1|D)\). In exact analogy, the 2D histogram approximation is computed from the samples for 2D bins in the indicator function. For understanding and presenting the results of Bayesian parameter inference, the set of 1D and 2D marginal distributions is the primary goal. Given samples from the full posterior, we have immediate access to <em>all</em> marginal distributions at once; i.e., there is no need for separate integration to obtain for example \(P(\theta_1|D)\) and \(P(\theta_2|D)\). This is a major benefit of the Monte Carlo method in conducting Bayesian inference.</p>
<h1><a class="anchor" id="sec-mcmc-foundations"></a>
Foundations</h1>
<p>The key ingredient in BAT is an implementation of the Metropolis algorithm to create a Markov chain; i.e. a sequence of (correlated) samples from the posterior. We use the shorthand MCMC for Markov chain Monte Carlo.</p>
<p>Efficient MCMC algorithms are the topic of past and current research. This section is a concise overview of the general idea and the algorithms available in BAT. For a broader overview, we refer the reader to the abundant literature; e.g.,</p><dl class="todo"><dt><b><a class="el" href="todo.html#_todo000008">Todo:</a></b></dt><dd>Robert+Casella, MCMC handbook.</dd></dl>
<p>In BAT, there are several variants of the random-walk Metropolis Hastings algorithm available. The basic idea is captured in the <a class="el" href="cha-mcmc.html#random-walk-2D">2D example plot</a>. Given an initial point \(x_0\), the Metropolis algorithm produces a sample in each iteration \(t=1 \dots\) as follows:</p>
<ul>
<li>Propose a new point \(y\)</li>
<li>Generate a number u from the uniform distribution on [0,1]</li>
<li>Set \(x_{t} = y\) if \( u &lt; \frac{P(y \cond D)}{P(x_{t-1} \cond D)}\)</li>
<li>Else stay, \(x_t = x_{t-1}\)</li>
</ul>
<p><a class="anchor" id="random-walk-2D"></a></p><div class="image">
<img src="random-walk.png" alt="random-walk.png"/>
<div class="caption">
2D random walk with the Metropolis algorithm.</div></div>
<p>In the example plot, the chain begins in the lower left corner. Rejected moves are indicated by the dashed arrow, accepted moves are indicated by the solid arrow. The circled number is the number of iterations the chain stays at a given point \(\vecth = (\theta_1, \theta_2)\).</p>
<p>In each iteration \(i\), one updates the estimate of the 1D marginal distribution \(P(\theta_1 | D)\) by adding the first coordinate of \(\vecth_i\) to a histogram. Repeat this for all other coordinates to update the other \(d-1\) 1D marginals.</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000009">Todo:</a></b></dt><dd>continue as in Lydia's email As a concrete example, suppose the chain has 5 iterations..</dd></dl>
<h1><a class="anchor" id="sec-convergence"></a>
Convergence</h1>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000010">Todo:</a></b></dt><dd>mixing, burn in, R value, multimodal problems</dd></dl>
<h1><a class="anchor" id="sec-mcmc-impl"></a>
Implementation in BAT</h1>
<p>Implementing the Metropolis algorithm, one has to decide on how to propose a new point based on the current point, that is one needs the <em>proposal distribution</em> \(q(y \cond x, \xi)\) with adjustable parameters \(\xi\). The main difference between MCMC algorithms is typically given by different choices of \(q\). The Metropolis algorithm doesn't specify which \(q\) to choose, so we can and have to select a function \(q\) and tune \(\xi\) according to our needs.</p>
<p>In BAT, the proposal is <em>symmetric</em> around the current point </p><p class="formulaDsp">
\begin{align} q(y \cond x, \xi) = q(x \cond y, \xi). \end{align}
</p>
<p>The Markov property implies that the proposal may only depend on the current point \(x\) and not on previous points. If the value of \(\xi\) is set based on a past sequence of iterations of the chain, we need two stages of sampling in BAT, the <em>prerun</em> and the <em>main run</em>. In the prerun, the chain is run and periodically \(\xi\) is updated based on the past iterations. In contrast, \(\xi\) is kept fixed in the main run to have a proper Markov chain.</p>
<h2><a class="anchor" id="sec-mcmc-prerun"></a>
Prerun</h2>
<p>During the prerun, the proposal is updated. BAT considers three criteria to decide when to end the prerun:</p>
<h3><a class="anchor" id="sec-mcmc-eff"></a>
Efficiency</h3>
<p>The <em>efficiency</em>, or acceptance rate, is the ratio of the accepted over the total number proposal moves. A small efficiency means the chain rarely moves but may then make a large move. A large efficiency means the chain explores well locally but may take a long time to explore the entire region of high probability. Optimality results exists only for very special cases: Roberts and Rosenthal showed that for a Gaussian target with \(d\) independent components and a Gaussian proposal, the optimal target efficiency is 23.4 % for \(d \geq 5\) is but should be larger for small \(d\); e.g., 44 % is best in one dimension <a class="el" href="citelist.html#CITEREF_rosenthal2011optimal">[11]</a> . Based on our experience, we use a default range for the efficiency as \([0.15, 0.35]\).</p>
<dl class="section see"><dt>See also</dt><dd><a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a4bb0f931005f762876bfb163ade4afc7">BCEngineMCMC::SetMinimumEfficiency</a>, <a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a70bf3ff35665dd856efbcfbd40f84c3d">BCEngineMCMC::SetMaximumEfficiency</a></dd></dl>
<h3><a class="anchor" id="sec-mcmc-Rvalue"></a>
R value</h3>
<p>The <em>R value</em> <a class="el" href="citelist.html#CITEREF_Gelman:1992">[3]</a> by Gelman and Rubin quantifies the estimated scale reduction of the uncertainty of an expectation value estimated with the samples if the chain were run infinitely long. Informally, it compares the mean and variance of the expectation value for a single chain with the corresponding results of multiple chains. If the chains mix despite different initial values, then we assume that they are independent of the initial value, the burn-in is over, and the samples produce reliable estimates of quantities of interest. For a single chain, the \(R\) value cannot be computed.</p>
<p>In BAT, we monitor the expectation value of each parameter and declare convergence if all R values are below a threshold. Note that the R values are estimated from batches of samples, and they usually decrease with more iterations but they may also increase, which usually is a clear indication that the chains do not mix, perhaps due to multiple modes that trap the chains.</p>
<dl class="section see"><dt>See also</dt><dd><a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a8002cb58c287691c2a69fc18b9b63d07">BCEngineMCMC::SetRValueParametersCriterion</a> Set that maximum R value for all parameters. <b>Default: 1.1</b></dd>
<dd>
<a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a26274873267b4ea07ff82795480ca53c">BCEngineMCMC::SetCorrectRValueForSamplingVariability</a> The strict definition of \(R\) corrects the sampling variability due finite batch size. <b>Default: false</b></dd>
<dd>
<a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#ac12ecd31b01c6b9157d7a34c195a9a51">BCEngineMCMC::GetRValueParameters</a> \(R\) values are computed during the prerun and they can be retrieved but not set.</dd></dl>
<h3><a class="anchor" id="sec-mcmc-prerun-length"></a>
Prerun length</h3>
<p>Defining convergence automatically based on the efficiency or the \(R\) value is convenient may be too conservative if the user knows a good initial value, a good proposal, etc. For more control the minimum and maximum length of the prerun can be set, too.</p>
<dl class="section see"><dt>See also</dt><dd><a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a4be0b2f087a6911c9f4e1ca66b2668bb">BCEngineMCMC::SetNIterationsPreRunMin</a>, <a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#a673f41ff4c667f81acdf7936173e3818">BCEngineMCMC::SetNIterationsPreRunMax</a></dd>
<dd>
<a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#abea983c2131efdb640175651948acd55">BCEngineMCMC::SetNIterationsPreRunCheck</a> sets the number of iterations between checks</dd></dl>
<p>If desired, the statistics can be cleared to remove the effect of a bad initial point with <a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#aee6c53619d87454dd93aac8c61893a4b">BCEngineMCMC::SetPreRunCheckClear</a> after some set of iterations</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000011">Todo:</a></b></dt><dd>A flow diagram might help</dd></dl>
<p>For the user's convenience, multiple settings related to precision of the Markov chain can be set at once using <a class="elRef" doxygen="/root/bat/doc/ref-guide/bat-ref.tag:../../ref-guide/html/" href="../../ref-guide/html/classBCEngineMCMC.html#abfe354986716fbc9bb9d1ebbd1b34cd6">BCEngineMCMC::SetPrecision</a>. The default setting is BCEngineMCMC::kMedium.</p>
<h2><a class="anchor" id="sec-mcmc-proposal"></a>
Proposal functions</h2>
<p>BAT offers two kinds of proposal function termed <em>factorized</em> and <em>multivariate</em>.</p>
<h3><a class="anchor" id="sec-factorized"></a>
Factorized proposal</h3>
<dl class="section since"><dt>Since</dt><dd>Factorized was the default and only choice prior to v1.0 and continues to be available using BCEngineMCMC::SetProposeMultivariate(true)</dd></dl>
<p>The factorized proposal in \(d\) dimensions is a product of 1D proposals.</p>
<p>We sequentially vary one parameter at a time and complete one iteration of the chain once a new point has been proposed in <em>every</em> direction. This means the chain attempts to perform a sequence of axis-aligned moves in one iteration.</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000012">Todo:</a></b></dt><dd>Easiest to understand would be pseudocode</dd></dl>
<p>Each 1D proposal is a Cauchy or Breit-Wigner function centered on the current point. The scale parameter is adapted in the prerun to achieve an acceptance rate in a given range that can be adjusted by the user. Note that there is a separate scale parameter in every dimension.</p>
<p>This means the posterior is called \(d\) times in every iteration. Since the acceptance rate</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000013">Todo:</a></b></dt><dd>to define before</dd></dl>
<p>is typically different from zero or one, the factorized proposal typically generates a new point in every iteration that differs from the previous point in some but not all dimensions.</p>
<h3><a class="anchor" id="sec-multivariate"></a>
Multivariate proposal</h3>
<dl class="section since"><dt>Since</dt><dd>1.0</dd></dl>
<p>Changing all \(d\) parameters at once within one iteration is an all-or-nothing approach. If the proposed move is accepted, all parameters have changed for the price of a single evaluation of the posterior. If the move is rejected, the new point is identical to the old point and the chain does not explore the parameter space.</p>
<p>We implement the adaptive algorithm <a class="el" href="citelist.html#CITEREF_Haario:2001">[5]</a> by Haario et al. In brief, the proposal is a multivariate Gaussian or Student's t distribution whose covariance is learned from the covariance of samples in the prerun. An overall scale factor is tuned to force the acceptance rate into a certain range.</p>
<dl class="todo"><dt><b><a class="el" href="todo.html#_todo000014">Todo:</a></b></dt><dd>Pseudocode</dd></dl>
<h2><a class="anchor" id="sec-mcmc-proposal-comparison"></a>
Comparison</h2>
<p>Comparing the factorized proposal to the multivariate proposal, we generally recommend the multivariate for most purposes.</p>
<p>Use the factorized proposal if you can speed up the computation of the posterior if you know that some parameters did not change. This can be useful if the computation is expensive if some but not all parameters change. </p>
</div></div><!-- contents -->
<!-- HTML footer for doxygen 1.8.8-->
<!-- start footer part -->
</div>
</div>
</div>
</div>
</div>
<!-- <hr class="footer"/><address class="footer"><small> -->
<!-- Generated on Tue May 8 2018 13:18:41 for BAT manual by &#160;<a href="http://www.doxygen.org/index.html"> -->
<!-- <img class="footer" src="doxygen.png" alt="doxygen"/> -->
<!-- </a> 1.8.11 -->
<!-- </small></address> -->
</body>
</html>
